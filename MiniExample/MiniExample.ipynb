{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small reproducible example to demonstrate the modelling pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Import relevant functions from other modules\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from Data.ImageData.select_tifs import copy_tif_files\n",
    "from Modelling.TrainTestSplit.TrainTestSplitNew import process_text_data, oversample_classes, split_data, generate_and_save_augmented_images\n",
    "from Data.ImageData.SplitImagesNew import extract_vignettes\n",
    "from Modelling.CNN.CNNnew import preprocess_data, create_tf_datasets, build_model, cnn_evaluate_model, plot_hist\n",
    "from Modelling.MLP.MLPnew import load_and_preprocess, perform_grid_search, mlp_evaluate_model\n",
    "from Modelling.CollaborativeModel.CollabModelNew import prepare_data, train_collaborative_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets\n",
    "\n",
    "Create subsample and merged datasets (bc csv data is too big for github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged = pd.read_csv(\"cleaned_merged.csv\")\n",
    "cleaned_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = cleaned_merged[\"Class\"].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant tif files\n",
    "source_dir = \"/Users/adelelauzon/Desktop/MSc/STA5243/HURON_OverlapTiffsWithPP\"\n",
    "output_dir = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/tifs_mini\"\n",
    "data_cleaned_path = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/cleaned_merged.csv\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_tif_files(source_dir, output_dir, data_cleaned_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the tif mosaics into particles\n",
    "vignettes_output = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/vignettes_mini\"\n",
    "extracted_particles_csv_path = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/extracted_particles.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_vignettes(data_cleaned_path, output_dir,vignettes_output, extracted_particles_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our class counts are so imbalanced, we will oversample Herpacticoida and Herpacticoida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = pd.read_csv(extracted_particles_csv_path)\n",
    "text_data = pd.read_csv(data_cleaned_path)\n",
    "text_all_cleaned = process_text_data(text_data, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles[particles[\"Class\"]==\"Bosmina_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the classes you want to oversample\n",
    "classes_to_oversample = ('Bosmina_1',)  \n",
    "train_img, val_img, test_img, train_text, val_text, test_text = split_data(particles, text_all_cleaned, classes_to_oversample, target_count=30)\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate augmented images for each oversampled class\n",
    "augmented_images = []\n",
    "for class_label in classes_to_oversample:\n",
    "    train_class = train_img[train_img['Class'] == class_label]\n",
    "    aug_images = generate_and_save_augmented_images(train_class, vignettes_output, class_label=class_label)\n",
    "    augmented_images.extend(aug_images)\n",
    "\n",
    "augmented_df = pd.DataFrame(augmented_images, columns=[\"Vignette\", \"Class\"])\n",
    "train_img = pd.concat([train_img, augmented_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "path_aug = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/vignettes_mini/20180430_Huron_057_2mm_rep1_000004_vign000001_aug_0_698.png\"\n",
    "path_orig = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/vignettes_mini/20180430_Huron_057_2mm_rep1_000004_vign000001.png\"\n",
    "orig = Image.open(path_orig)\n",
    "aug = Image.open(path_aug)\n",
    "display(orig)\n",
    "display(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_img.to_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_train.csv\", index=False)\n",
    "val_img.to_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_val.csv\", index=False)\n",
    "test_img.to_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_test.csv\", index=False)\n",
    "train_text.to_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_train.csv\", index=False)\n",
    "val_text.to_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_val.csv\", index=False)\n",
    "test_text.to_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_test.csv\", index=False)\n",
    "print(\"Data augmentation and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text[\"ParticleID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/vignettes_mini/\"\n",
    "train_img, val_img, test_img, num_classes = preprocess_data(train_img, val_img, test_img, base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = create_tf_datasets(train_img, val_img, test_img, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_ds, epochs=10, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_output_dir = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/cnn_model_accuracy.png\"\n",
    "plot_hist(hist, fig_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output_dir = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/cnn_performance_metrics.txt\"\n",
    "model_output_dir = '/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/cnn_final_model.keras'\n",
    "\n",
    "model.save(model_output_dir)\n",
    "cnn_evaluate_model(model, test_ds, test_img, metrics_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample\"\n",
    "model_output_dir = '/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/mlp_final_model.keras'\n",
    "fig_output_dir = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/mlp_model_accuracy.png\"\n",
    "metrics_output_dir = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/performance_metrics.txt\"\n",
    "\n",
    "text_train, text_val, text_test = [load_and_preprocess(file, base_path) for file in [\"text_train.csv\", \"text_val.csv\", \"text_test.csv\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and label extraction\n",
    "feature_columns = [col for col in text_train.columns if not col.startswith('class_')]\n",
    "class_columns = [col for col in text_train.columns if col.startswith('class_')]\n",
    "\n",
    "X_train, y_train = text_train[feature_columns].to_numpy(), text_train[class_columns].to_numpy()\n",
    "X_val, y_val = text_val[feature_columns].to_numpy(), text_val[class_columns].to_numpy()\n",
    "X_test, y_test = text_test[feature_columns].to_numpy(), text_test[class_columns].to_numpy()\n",
    "\n",
    "input_shape, num_classes = X_train.shape[1], len(class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = perform_grid_search(X_train, y_train, X_val, y_val, input_shape, num_classes, fig_output_dir, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model\n",
    "best_model.save(model_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_evaluate_model(best_model, X_train, y_train, X_test, y_test,X_val, y_val, metrics_output_dir, fig_output_dir, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = pd.read_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_train.csv\")\n",
    "image_val = pd.read_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_val.csv\")\n",
    "image_test = pd.read_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_test.csv\")\n",
    "\n",
    "text_train = pd.read_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_train.csv\")\n",
    "text_val = pd.read_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_val.csv\")\n",
    "text_test = pd.read_csv(\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (300, 300)\n",
    "batch_size = 64\n",
    "\n",
    "# Paths\n",
    "image_paths = [\n",
    "\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_train.csv\",\n",
    "\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_val.csv\",\n",
    "\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/image_test.csv\"\n",
    "]\n",
    "\n",
    "text_paths = [\n",
    "\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_train.csv\",\n",
    "\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_val.csv\",\n",
    "\"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/text_test.csv\"\n",
    "]\n",
    "\n",
    "vignette_path = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/vignettes_mini/\"\n",
    "output_dir = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample\"\n",
    "mlp_path = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/mlp_final_model.keras\"\n",
    "cnn_path = \"/Users/adelelauzon/Desktop/MSc/STA5243/2453Github/MiniExample/cnn_final_model.keras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "# 1. Process Image Data\n",
    "image_size = (300, 300)\n",
    "batch_size = 64\n",
    "trainAttrX, trainImagesX, trainY, valAttrX, valImagesX, valY, testAttrX, testImagesX, testY, num_classes = prepare_data(image_paths, text_paths, vignette_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save model\n",
    "train_collaborative_model(mlp_path, cnn_path, num_classes, output_dir, trainAttrX, trainImagesX, trainY, valAttrX, valImagesX, valY, num_epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
